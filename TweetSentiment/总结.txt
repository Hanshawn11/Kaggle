
关键：寻找token偏移量offset
生成text长度的0向量， text字符串定位answer的开始位置，加answer长度为结束位置,cover部分为1, 记录encode后每个token的起始位置，
覆盖1的token被认为是答案的一部分, 记录这些token，第一个和最后一个token则是真正的起始位置, start 0矩阵， n*m, n 为数据量， m为最大长度, 设置start token位置为1, end 0矩阵同理

random seed 对结果有 +- 0.02左右的影响，原因不明

标签平滑:
交叉熵（Cross-Entropy）损失函数， −[ylogp+(1−y)log(1−p)]

如果分类准确，交叉熵损失函数的结果是0, 否则交叉熵为无穷大
在分类任务中，我们通常对类别标签的编码使用[0,1,2,…]这种形式。在深度学习中，通常在全连接层的最后一层，加入一个softmax来计算输入数据属于每个类别的概率，
并把概率最高的作为这个类别的输入，然后使用交叉熵作为损失函数。这会导致模型对正确分类的情况奖励最大,错误分类惩罚最大。
事实上标签有可能也不是完全正确， 所以这种方式可能会过拟合。

平滑例： one-hot * 1-x + x / len(one-hot)
[0,1]×(1−0.1)+0.1/2=[0.05,0.95]

多模型融合可以提高泛化能力，这次仅仅做了不同的输出层， 取了在cross-validation 上各层中表现超过平均水平的做融合bagging。各模型权重用jaccard 得分做softmax归一之后得到。
可能基模型差别更大范化能力会更好。

伪标签， 用learderborad上变现最好的模型组合生成伪标签， 取15%加入训练数据。

jaccrad 评价指标不合理, label->happy! 和 answer->happy， 得分为0， 所以要关注生成结果的标点符号。

stacking方法可以获得更好的结果，用bagging模型输出的logistic+ test data 再输入到一个简单的模型，最后的得分会更高。
